{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to AutoMS Summary AutoMS is an open-source Python library for mass spectrometry, specifically for the analysis of metabolomics data in Python. AutoMS is available for Windows, Linux and macOS. AutoMS is a comprehensive software tool designed to facilitate metabolomics data analysis. It offers a range of functionalities that aid in the processing and interpretation of metabolomics data. Here is a detailed summary of each module within AutoMS: Feature Detection: This module focuses on identifying and extracting relevant features from raw metabolomics data. It employs advanced algorithms to detect peaks or signals representing metabolites within mass spectrometry or chromatography data. Metabolite Annotation: The metabolite annotation module plays a crucial role in identifying the detected features. AutoMS compares the experimental data against reference spectral libraries, such as the MassBank or GNPS libraries. By performing spectral matching, it enables the identification and confirmation of metabolites based on their characteristic mass spectra. Statistical Analysis: The statistical analysis module within AutoMS offers a suite of powerful statistical methods tailored for metabolomics data. It allows researchers to perform various statistical tests, including t-tests, multivariate analysis, and machine learning analysis. This facilitates the identification of significant differences between groups or conditions, enabling valuable insights into metabolic changes. Molecular Network: AutoMS incorporates a molecular network analysis module, which utilizes network-based algorithms to explore the relationships between metabolites based on their structural similarities and/or shared biosynthetic pathways. This module aids in the elucidation of complex metabolic networks and the discovery of potential biomarkers or key metabolites. Enhancement Analysis: The enhancement analysis module focuses on identifying factors or conditions that lead to the alteration of specific metabolic pathways or biological functions. It assesses the enrichment of metabolites associated with particular pathways or gene sets, providing insights into the underlying mechanisms driving metabolic changes. Documentation Feature Extraction Feature Annotation Statistical Analysis Network Analysis Enhancement Analysis Sources on GitHub AutoMS2 GitHub Changelog verision 1.0: first release at 20YY.MM.DD Citations Main citations (papers of this software) Hongchao Ji, Jing Tian. Deep denoising autoencoder-assisted continuous scoring of peak quality in high-resolution LC\u2212MS data. Chemometrics and Intelligent Laboratory Systems 2022, 104694. Additional citations (algorithms integrated in this software) Hongchao Ji, Fanjuan Zeng, Yamei Xu, et al. KPIC2: An Effective Framework for Mass Spectrometry-Based Metabolomics Using Pure Ion Chromatograms. Analytical Chemistry 2017, 89 (14), 7631\u20137640. Hongchao Ji, Yamei Xu, Hongmei Lu, Zhimin Zhang. Deep MS/MS-Aided Structural-Similarity Scoring for Unknown Metabolite Identification. Analytical Chemistry 2019, 91 (9), 5629\u20135637. Huimin Zhu, Yi Chen, Cha Liu, et al. Feature Extraction for LC\u2013MS via Hierarchical Density Clustering. Chromatographia 2019, 10(82): 1449-1457. Zhimin Zhang, Xia Tong, Ying Peng, et al. Multiscale peak detection in wavelet space. The Analyst 2015, 23(140): 7955-7964. Yuanyue Li, Tobias Kind, Jacob Folz, et al. Spectral entropy outperforms MS/MS dot product similarity for small-molecule compound identification. Nature Methods 12(8): 1524-1531. Florian Huber, Stefan Verhoeven, Christiaan Meijer, et al. matchms - processing and similarity evaluation of mass spectrometry data. Journal of Open Source Software 52(5):2411.","title":"Home"},{"location":"#welcome-to-automs","text":"","title":"Welcome to AutoMS"},{"location":"#summary","text":"AutoMS is an open-source Python library for mass spectrometry, specifically for the analysis of metabolomics data in Python. AutoMS is available for Windows, Linux and macOS. AutoMS is a comprehensive software tool designed to facilitate metabolomics data analysis. It offers a range of functionalities that aid in the processing and interpretation of metabolomics data. Here is a detailed summary of each module within AutoMS: Feature Detection: This module focuses on identifying and extracting relevant features from raw metabolomics data. It employs advanced algorithms to detect peaks or signals representing metabolites within mass spectrometry or chromatography data. Metabolite Annotation: The metabolite annotation module plays a crucial role in identifying the detected features. AutoMS compares the experimental data against reference spectral libraries, such as the MassBank or GNPS libraries. By performing spectral matching, it enables the identification and confirmation of metabolites based on their characteristic mass spectra. Statistical Analysis: The statistical analysis module within AutoMS offers a suite of powerful statistical methods tailored for metabolomics data. It allows researchers to perform various statistical tests, including t-tests, multivariate analysis, and machine learning analysis. This facilitates the identification of significant differences between groups or conditions, enabling valuable insights into metabolic changes. Molecular Network: AutoMS incorporates a molecular network analysis module, which utilizes network-based algorithms to explore the relationships between metabolites based on their structural similarities and/or shared biosynthetic pathways. This module aids in the elucidation of complex metabolic networks and the discovery of potential biomarkers or key metabolites. Enhancement Analysis: The enhancement analysis module focuses on identifying factors or conditions that lead to the alteration of specific metabolic pathways or biological functions. It assesses the enrichment of metabolites associated with particular pathways or gene sets, providing insights into the underlying mechanisms driving metabolic changes.","title":"Summary"},{"location":"#documentation","text":"Feature Extraction Feature Annotation Statistical Analysis Network Analysis Enhancement Analysis","title":"Documentation"},{"location":"#sources-on-github","text":"AutoMS2 GitHub","title":"Sources on GitHub"},{"location":"#changelog","text":"verision 1.0: first release at 20YY.MM.DD","title":"Changelog"},{"location":"#citations","text":"Main citations (papers of this software) Hongchao Ji, Jing Tian. Deep denoising autoencoder-assisted continuous scoring of peak quality in high-resolution LC\u2212MS data. Chemometrics and Intelligent Laboratory Systems 2022, 104694. Additional citations (algorithms integrated in this software) Hongchao Ji, Fanjuan Zeng, Yamei Xu, et al. KPIC2: An Effective Framework for Mass Spectrometry-Based Metabolomics Using Pure Ion Chromatograms. Analytical Chemistry 2017, 89 (14), 7631\u20137640. Hongchao Ji, Yamei Xu, Hongmei Lu, Zhimin Zhang. Deep MS/MS-Aided Structural-Similarity Scoring for Unknown Metabolite Identification. Analytical Chemistry 2019, 91 (9), 5629\u20135637. Huimin Zhu, Yi Chen, Cha Liu, et al. Feature Extraction for LC\u2013MS via Hierarchical Density Clustering. Chromatographia 2019, 10(82): 1449-1457. Zhimin Zhang, Xia Tong, Ying Peng, et al. Multiscale peak detection in wavelet space. The Analyst 2015, 23(140): 7955-7964. Yuanyue Li, Tobias Kind, Jacob Folz, et al. Spectral entropy outperforms MS/MS dot product similarity for small-molecule compound identification. Nature Methods 12(8): 1524-1531. Florian Huber, Stefan Verhoeven, Christiaan Meijer, et al. matchms - processing and similarity evaluation of mass spectrometry data. Journal of Open Source Software 52(5):2411.","title":"Citations"},{"location":"API_guide/","text":"API Guide This is an overview over all classes available in AutoMS. AutoMSData The AutoMSData class represents an object for handling mass spectrometry data. Methods: init (self, ion_mode='positive') : Initialize the AutoMSData object with an optional ion_mode parameter specifying the ionization mode. load_files(self, data_path) : Load data files from the specified directory path. find_features(self, min_intensity, mass_inv=1, rt_inv=30, min_snr=3, max_items=50000) : Find features in the loaded data files using the HPIC algorithm. evaluate_features(self) : Evaluate the extracted features using peak evaluation. match_features(self, method = 'simple', mz_tol = 0.01, rt_tol = 20, min_frac = 0.5) : Match and filter extracted features using feature matching. load_features_msdial(self, msdial_path) : Load feature extraction results from MS-DIAL into AutoMS. match_features_with_ms2(self, mz_tol = 0.01, rt_tol = 15) : Match features with corresponding MS/MS spectra. search_library(self, lib_path, method = 'entropy', ms1_da = 0.01, ms2_da = 0.05, threshold = 0.5) : Search a library for metabolite annotation based on the feature table. refine_annotated_table(self, value_columns) : Refine the annotated feature table by selecting representative entries for each annotated compound. load_external_annotation(self, annotation_file, mz_tol = 0.01, rt_tol = 10) : Load external annotation information from a file and match it with the feature table. export_ms2_to_mgf(self, save_path) : Export feature MS2 spectra to an MGF file. load_deepmass_annotation(self, deepmass_dir) : Load annotation information from DeepMass results and link it with the feature table. save_project(self, save_path) : Save the current project to a file. load_project(self, save_path) : Load a project from a file. Attributes: data_path : str, The path of the dataset of the experiment. ion_mode : str, The ionization mode of the experiment. peaks : dict, Extracted peaks via HPIC, which will be None if features are load from exterinal software. feature_table : DataFrame, Extracted features with all obtained information from the executed methods. AutoMSFeature Methods: - init (self, feature_table=None, sample_list=None) : Initialize AutoMSFeature object. - update_sample_name(self, namelist) : Update the sample names in the feature table. - append_feature_table(self, feature_object) : Append another feature table to the existing feature table. - preprocessing(self, impute_method='KNN', outlier_threshold=3, rsd_threshold=0.3, min_frac=0.5, qc_samples=None, group_info=None) : Preprocess the feature table by imputing missing values, removing outliers, and scaling the data. - refine_annotated_table(self) : Refine the feature table with annotation by selecting representative entries for each compound. - perform_dimensional_reduction(self, group_info=None, method='PCA', annotated_only=True) : Perform dimensional reduction on the feature table for visualization. - perform_PLSDA(self, group_info=None, n_components=2, n_permutations=1000, annotated_only=True, loo_test=True, permutation_test=True) : Perform Partial Least Squares Discriminant Analysis (PLSDA) on the feature table. - perform_RandomForest(self, group_info=None, annotated_only=True, loo_test=True) : Perform Random Forest analysis on the feature table. - perform_GradientBoost(self, model='XGBoost', group_info=None, annotated_only=True, loo_test=True) : Perform Gradient Boosting analysis on the feature table. - perform_T_Test(self, group_info=None, annotated_only=True) : Perform T-Test analysis on the feature table. - select_biomarker(self, criterion={'PLS_VIP': ['>', 1.5]}, combination='union', annotated_only=True) : Select biomarkers from the feature table based on given criteria. - perform_heatmap(self, biomarker_only=True, group_info=None, hide_xticks=False, hide_ytick=False) : Perform heatmap visualization of the feature table or biomarker table. - perform_molecular_network(self, threshold=0.5, target_compound=None, group_info=None) : Perform molecular network analysis based on the feature table. - perform_enrichment_analysis(self, organism=\"hsa\", pvalue_cutoff=0.05, adj_method=\"fdr_bh\") : Perform enrichment analysis on the biomarker table. - save_project(self, save_path) : Save the current project to a file. - load_project(self, save_path) : Load a project from a file. Attributes: files : list, The list of sample names corresponding to the columns in the feature table. feature_table : DataFrame, Extracted features with all obtained information from the executed methods. feature_table_annotated : DataFrame, Extracted features which have been annotated. biomarker_table : DataFrame, Table of selected biomarker.","title":"API guide"},{"location":"API_guide/#api-guide","text":"This is an overview over all classes available in AutoMS.","title":"API Guide"},{"location":"API_guide/#automsdata","text":"The AutoMSData class represents an object for handling mass spectrometry data. Methods: init (self, ion_mode='positive') : Initialize the AutoMSData object with an optional ion_mode parameter specifying the ionization mode. load_files(self, data_path) : Load data files from the specified directory path. find_features(self, min_intensity, mass_inv=1, rt_inv=30, min_snr=3, max_items=50000) : Find features in the loaded data files using the HPIC algorithm. evaluate_features(self) : Evaluate the extracted features using peak evaluation. match_features(self, method = 'simple', mz_tol = 0.01, rt_tol = 20, min_frac = 0.5) : Match and filter extracted features using feature matching. load_features_msdial(self, msdial_path) : Load feature extraction results from MS-DIAL into AutoMS. match_features_with_ms2(self, mz_tol = 0.01, rt_tol = 15) : Match features with corresponding MS/MS spectra. search_library(self, lib_path, method = 'entropy', ms1_da = 0.01, ms2_da = 0.05, threshold = 0.5) : Search a library for metabolite annotation based on the feature table. refine_annotated_table(self, value_columns) : Refine the annotated feature table by selecting representative entries for each annotated compound. load_external_annotation(self, annotation_file, mz_tol = 0.01, rt_tol = 10) : Load external annotation information from a file and match it with the feature table. export_ms2_to_mgf(self, save_path) : Export feature MS2 spectra to an MGF file. load_deepmass_annotation(self, deepmass_dir) : Load annotation information from DeepMass results and link it with the feature table. save_project(self, save_path) : Save the current project to a file. load_project(self, save_path) : Load a project from a file. Attributes: data_path : str, The path of the dataset of the experiment. ion_mode : str, The ionization mode of the experiment. peaks : dict, Extracted peaks via HPIC, which will be None if features are load from exterinal software. feature_table : DataFrame, Extracted features with all obtained information from the executed methods.","title":"AutoMSData"},{"location":"API_guide/#automsfeature","text":"Methods: - init (self, feature_table=None, sample_list=None) : Initialize AutoMSFeature object. - update_sample_name(self, namelist) : Update the sample names in the feature table. - append_feature_table(self, feature_object) : Append another feature table to the existing feature table. - preprocessing(self, impute_method='KNN', outlier_threshold=3, rsd_threshold=0.3, min_frac=0.5, qc_samples=None, group_info=None) : Preprocess the feature table by imputing missing values, removing outliers, and scaling the data. - refine_annotated_table(self) : Refine the feature table with annotation by selecting representative entries for each compound. - perform_dimensional_reduction(self, group_info=None, method='PCA', annotated_only=True) : Perform dimensional reduction on the feature table for visualization. - perform_PLSDA(self, group_info=None, n_components=2, n_permutations=1000, annotated_only=True, loo_test=True, permutation_test=True) : Perform Partial Least Squares Discriminant Analysis (PLSDA) on the feature table. - perform_RandomForest(self, group_info=None, annotated_only=True, loo_test=True) : Perform Random Forest analysis on the feature table. - perform_GradientBoost(self, model='XGBoost', group_info=None, annotated_only=True, loo_test=True) : Perform Gradient Boosting analysis on the feature table. - perform_T_Test(self, group_info=None, annotated_only=True) : Perform T-Test analysis on the feature table. - select_biomarker(self, criterion={'PLS_VIP': ['>', 1.5]}, combination='union', annotated_only=True) : Select biomarkers from the feature table based on given criteria. - perform_heatmap(self, biomarker_only=True, group_info=None, hide_xticks=False, hide_ytick=False) : Perform heatmap visualization of the feature table or biomarker table. - perform_molecular_network(self, threshold=0.5, target_compound=None, group_info=None) : Perform molecular network analysis based on the feature table. - perform_enrichment_analysis(self, organism=\"hsa\", pvalue_cutoff=0.05, adj_method=\"fdr_bh\") : Perform enrichment analysis on the biomarker table. - save_project(self, save_path) : Save the current project to a file. - load_project(self, save_path) : Load a project from a file. Attributes: files : list, The list of sample names corresponding to the columns in the feature table. feature_table : DataFrame, Extracted features with all obtained information from the executed methods. feature_table_annotated : DataFrame, Extracted features which have been annotated. biomarker_table : DataFrame, Table of selected biomarker.","title":"AutoMSFeature"},{"location":"about/","text":"About Group Information Our research group is dedicated to interdisciplinary research in computer science, analytical chemistry, and chemical biology. Using chemometrics and chemoinformatics as the main tools and metabolomics as the starting point, we develop a series of new algorithms and technologies for data analysis in complex systems analysis, focusing on the core scientific problem of predicting unknown small molecule structures and functions in complex systems. Group Website Group of Machine Learning and Computational Metabolomics","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#group-information","text":"Our research group is dedicated to interdisciplinary research in computer science, analytical chemistry, and chemical biology. Using chemometrics and chemoinformatics as the main tools and metabolomics as the starting point, we develop a series of new algorithms and technologies for data analysis in complex systems analysis, focusing on the core scientific problem of predicting unknown small molecule structures and functions in complex systems.","title":"Group Information"},{"location":"about/#group-website","text":"Group of Machine Learning and Computational Metabolomics","title":"Group Website"},{"location":"about/#_1","text":"","title":""},{"location":"datasets/","text":"Datasets This is a list of publicly available datasets of MS-based metabolomics study of our laboratory and user contribution. Any researchers can access and re-analyze the datasets under CC-BY-NC v4.0 License. Each item include sample information, experimental protocol, raw data and saved AutoMS object. Contact jihongchao@caas.cn for dataset contribution. Dataset of 600 mixed standards Sample Information : comming soon... Experimental Protocol : comming soon... Download Link : comming soon... Citation : comming soon... Data resource for three species of pogostemon cablin Sample Information : comming soon... Experimental Protocol : comming soon... Download Link : comming soon... Citation : comming soon...","title":"Datasets"},{"location":"datasets/#datasets","text":"This is a list of publicly available datasets of MS-based metabolomics study of our laboratory and user contribution. Any researchers can access and re-analyze the datasets under CC-BY-NC v4.0 License. Each item include sample information, experimental protocol, raw data and saved AutoMS object. Contact jihongchao@caas.cn for dataset contribution.","title":"Datasets"},{"location":"datasets/#dataset-of-600-mixed-standards","text":"Sample Information : comming soon... Experimental Protocol : comming soon... Download Link : comming soon... Citation : comming soon...","title":"Dataset of 600 mixed standards"},{"location":"datasets/#data-resource-for-three-species-of-pogostemon-cablin","text":"Sample Information : comming soon... Experimental Protocol : comming soon... Download Link : comming soon... Citation : comming soon...","title":"Data resource for three species of pogostemon cablin"},{"location":"enhancement_analysis/","text":"Enhancement Analysis Enrichment analysis is a bioinformatics method used to identify overrepresented biological terms or functional categories within a set of genes, proteins, or metabolites of interest. It helps researchers gain insights into the biological significance of their experimental results by determining whether specific functional annotations or pathways are enriched in the dataset compared to what would be expected by chance. Here's an example code snippet: # after Feature Detection, Metabolite Annotation and Statistical Analysis automs_hpic_feat.select_biomarker(criterion = {'PLS_VIP': ['>', 1.2]}) automs_hpic_feat.perform_enrichment_analysis(self, organism=\"hsa\", pvalue_cutoff = 0.05, adj_method = \"fdr_bh\") Parameters : perform_enrichment_analysis organism (str): The organism for enrichment analysis. Default is \"hsa\" (human). pvalue_cutoff (float): The p-value cutoff for significant enrichment. Default is 0.05. adj_method (str): The adjustment method for multiple testing correction. Default is \"fdr_bh\".","title":"Enhancement Analysis"},{"location":"enhancement_analysis/#enhancement-analysis","text":"Enrichment analysis is a bioinformatics method used to identify overrepresented biological terms or functional categories within a set of genes, proteins, or metabolites of interest. It helps researchers gain insights into the biological significance of their experimental results by determining whether specific functional annotations or pathways are enriched in the dataset compared to what would be expected by chance. Here's an example code snippet: # after Feature Detection, Metabolite Annotation and Statistical Analysis automs_hpic_feat.select_biomarker(criterion = {'PLS_VIP': ['>', 1.2]}) automs_hpic_feat.perform_enrichment_analysis(self, organism=\"hsa\", pvalue_cutoff = 0.05, adj_method = \"fdr_bh\") Parameters : perform_enrichment_analysis organism (str): The organism for enrichment analysis. Default is \"hsa\" (human). pvalue_cutoff (float): The p-value cutoff for significant enrichment. Default is 0.05. adj_method (str): The adjustment method for multiple testing correction. Default is \"fdr_bh\".","title":"Enhancement Analysis"},{"location":"feature_annotation/","text":"pre { overflow-y: auto; max-height: 300px; } Annotation of Extracted Features Feature annotation is the process of assigning putative identities or annotations to detected features in metabolomics experiments. It involves associating the detected features with known or predicted metabolites present in databases or reference libraries. Annotation with Library Search AutoMS provides library search algorithm based on SpectralEntropy package. 43 different spectral similarity algorithms can be used for MS/MS spectral comparison. Here's an example code snippet: \"\"\" # Feature Extraction and Matching automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") automs_hpic_pos.find_features(min_intensity=20000, max_items=100000) automs_hpic_pos.match_features() \"\"\" # Match features with corresponding MS/MS spectra automs_hpic_pos.match_features_with_ms2() # Search a library for metabolite annotation based on the feature table automs_hpic_pos.search_library(\"Library/references_spectrums_positive.pickle\") Parameters : match_features_with_ms2 mz_tol (float): The m/z tolerance for matching features with spectra. Default is 0.01. rt_tol (float): The retention time tolerance for matching features with spectra. Default is 15. search_library lib_path (str): The path to the library file. method (str): The method for library search. Default is 'entropy'. ms1_da (float): The m/z tolerance for matching MS1 masses. Default is 0.01. ms2_da (float): The m/z tolerance for matching MS2 masses. Default is 0.05. threshold (float): The annotation confidence threshold. Default is 0.5. In this example, the code creates an AutoMSData object with the ion mode set to 'positive'. The data files are then loaded from the specified directory. Features are found in the loaded data using the specified parameters. Feature matching is performed, followed by feature matching with MS2 spectra. Finally, the feature annotation step is carried out using a library stored in the specified pickle file (\"Library/references_spectrums_positive.pickle\"). Supported similarity method : \"entropy\": Entropy distance \"unweighted_entropy\": Unweighted entropy distance \"euclidean\": Euclidean distance \"manhattan\": Manhattan distance \"chebyshev\": Chebyshev distance \"squared_euclidean\": Squared Euclidean distance \"fidelity\": Fidelity distance \"matusita\": Matusita distance \"squared_chord\": Squared-chord distance \"bhattacharya_1\": Bhattacharya 1 distance \"bhattacharya_2\": Bhattacharya 2 distance \"harmonic_mean\": Harmonic mean distance \"probabilistic_symmetric_chi_squared\": Probabilistic symmetric \u03c72 distance \"ruzicka\": Ruzicka distance \"roberts\": Roberts distance \"intersection\": Intersection distance \"motyka\": Motyka distance \"canberra\": Canberra distance \"baroni_urbani_buser\": Baroni-Urbani-Buser distance \"penrose_size\": Penrose size distance \"mean_character\": Mean character distance \"lorentzian\": Lorentzian distance \"penrose_shape\": Penrose shape distance \"clark\": Clark distance \"hellinger\": Hellinger distance \"whittaker_index_of_association\": Whittaker index of association distance \"symmetric_chi_squared\": Symmetric \u03c72 distance \"pearson_correlation\": Pearson/Spearman Correlation Coefficient \"improved_similarity\": Improved Similarity \"absolute_value\": Absolute Value Distance \"dot_product\": Dot-Product (cosine) \"dot_product_reverse\": Reverse dot-Product (cosine) \"spectral_contrast_angle\": Spectral Contrast Angle \"wave_hedges\": Wave Hedges distance \"cosine\": Cosine distance \"jaccard\": Jaccard distance \"dice\": Dice distance \"inner_product\": Inner Product distance \"divergence\": Divergence distance \"avg_l\": Avg (L1, L\u221e) distance \"vicis_symmetric_chi_squared_3\": Vicis-Symmetric \u03c72 3 distance \"ms_for_id_v1\": MSforID distance version 1 \"ms_for_id\": MSforID distance \"weighted_dot_product\": Weighted dot product distance\" How to Build a Library library should be stored in the specified pickle file, which is a list of matchms::Spectrum object. Here's an example code snippet of how to build library with GNPS data. GNPS data can be downloand at url import os import pickle import numpy as np from tqdm import tqdm from matchms.importing import load_from_mgf # Setting the path to the data directory path_data = os.path.join('D:/All_MSDatabase/GNPS_all') # Creating the full path to the MGF file filename = os.path.join(path_data, 'ALL_GNPS.mgf') # Loading spectrums from the MGF file using the 'load_from_mgf' function and creating a list of spectrums spectrums = [s for s in tqdm(load_from_mgf(filename))] from matchms.filtering import default_filters # Importing a function from the 'matchms.filtering' module from matchms.filtering import add_parent_mass, derive_adduct_from_name # Importing functions from the 'matchms.filtering' module # Defining a function to apply filters to a spectrum def apply_filters(s): s = default_filters(s) # Applying default filters to the spectrum s = derive_adduct_from_name(s) # Deriving the adduct from the spectrum's name s = add_parent_mass(s, estimate_from_adduct=True) # Adding the parent mass to the spectrum return s # Applying filters to the spectrums and creating a new list of filtered spectrums spectrums = [apply_filters(s) for s in tqdm(spectrums) if s is not None] # Saving the filtered spectrums as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) from matchms.filtering import harmonize_undefined_inchikey, harmonize_undefined_inchi, harmonize_undefined_smiles # Importing functions from the 'matchms.filtering' module from matchms.filtering import repair_inchi_inchikey_smiles # Importing a function from the 'matchms.filtering' module # Defining a function to clean the metadata of a spectrum def clean_metadata(s): s = harmonize_undefined_inchikey(s) # Harmonizing undefined InChI keys in the spectrum s = harmonize_undefined_inchi(s) # Harmonizing undefined InChI in the spectrum s = harmonize_undefined_smiles(s) # Harmonizing undefined SMILES in the spectrum s = repair_inchi_inchikey_smiles(s) # Repairing InChI, InChI key, and SMILES in the spectrum return s # Cleaning the metadata of the spectrums and creating a new list of spectrums with cleaned metadata spectrums = [clean_metadata(s) for s in tqdm(spectrums) if s is not None] # Saving the spectrums with cleaned metadata as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) from matchms.filtering import derive_inchi_from_smiles, derive_smiles_from_inchi # Importing functions from the 'matchms.filtering' module from matchms.filtering import derive_inchikey_from_inchi # Importing a function from the 'matchms.filtering' module # Defining a function to further clean the metadata of a spectrum def clean_metadata2(s): s = derive_inchi_from_smiles(s) # Deriving InChI from SMILES in the spectrum s = derive_smiles_from_inchi(s) # Deriving SMILES from InChI in the spectrum s = derive_inchikey_from_inchi(s) # Deriving InChI key from InChI in the spectrum return s # Further cleaning the metadata of the spectrums and creating a new list of spectrums with further cleaned metadata spectrums = [clean_metadata2(s) for s in tqdm(spectrums) if s is not None] # Saving the spectrums with further cleaned metadata as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) # Looping over each spectrum and modifying the compound name for spectrum in tqdm(spectrums): name_original = spectrum.get(\"compound_name\") # Getting the original compound name from the spectrum name = name_original.replace(\"F dial M\", \"\") # Removing \"F dial M\" from the compound name # Remove last word if likely not correct if name.split(\" \")[-1] in [\"M\", \"M?\", \"?\", \"M+2H/2\", \"MS34+Na\", \"M]\", \"Cat+M]\", \"Unk\", \"--\"]: name = \" \".join(name.split(\" \")[:-1]).strip() # Removing the last word from the compound name if name != name_original: print(f\"Changed compound name from {name_original} to {name}.\") # Printing the changed compound name spectrum.set(\"compound_name\", name) # Setting the modified compound name in the spectrum # Looping over each spectrum and modifying the ion mode for spec in spectrums: if spec.get(\"adduct\") in ['[M+CH3COO]-/[M-CH3]-', '[M-H]-/[M-Ser]-', '[M-CH3]-']: if spec.get(\"ionmode\") != \"negative\": spec.set(\"ionmode\", \"negative\") # Setting the ion mode to \"negative\" if specific adducts are present from matchms.filtering import normalize_intensities # Importing a function from the 'matchms.filtering' module from matchms.filtering import require_minimum_number_of_peaks # Importing a function from the 'matchms.filtering' module from matchms.filtering import select_by_mz # Importing a function from the 'matchms.filtering' module # Defining a function to post-process a spectrum def post_process(s): s = normalize_intensities(s) # Normalizing the intensities of the spectrum s = select_by_mz(s, mz_from=10.0, mz_to=1000) # Selecting peaks within a specific m/z range s = require_minimum_number_of_peaks(s, n_required=5) # Requiring a minimum number of peaks in the spectrum return s # Post-processing the spectrums and creating a new list of post-processed spectrums spectrums = [post_process(s) for s in tqdm(spectrums)] # Saving the post-processed spectrums as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) spectrums = [s for s in spectrums if s is not None] # Filtering out any None values from the spectrums spectrums_positive = [] # Creating an empty list for positive ion mode spectrums spectrums_negative = [] # Creating an empty list for negative ion mode spectrums # Looping over each spectrum and categorizing them based on ion mode for i, spec in enumerate(spectrums): if spec.get(\"ionmode\") == \"positive\": spectrums_positive.append(spec) # Adding the spectrum to the positive ion mode list elif spec.get(\"ionmode\") == \"negative\": spectrums_negative.append(spec) # Adding the spectrum to the negative ion mode list else: print(f\"No ionmode found for spectrum {i} ({spec.get('ionmode')})\") # Printing a message if no ion mode is found # Pickling the negative ion mode spectrums and saving them as a pickle file pickle.dump(spectrums_negative, open(os.path.join(path_data, 'ALL_GNPS_220601_negative_cleaned.pickle'), \"wb\")) # Pickling the positive ion mode spectrums and saving them as a pickle file pickle.dump(spectrums_positive, open(os.path.join(path_data, 'ALL_GNPS_220601_positive_cleaned.pickle'), \"wb\")) Annotation with DeepMASS comming soon","title":"Feature Annotation"},{"location":"feature_annotation/#annotation-of-extracted-features","text":"Feature annotation is the process of assigning putative identities or annotations to detected features in metabolomics experiments. It involves associating the detected features with known or predicted metabolites present in databases or reference libraries.","title":"Annotation of Extracted Features"},{"location":"feature_annotation/#annotation-with-library-search","text":"AutoMS provides library search algorithm based on SpectralEntropy package. 43 different spectral similarity algorithms can be used for MS/MS spectral comparison. Here's an example code snippet: \"\"\" # Feature Extraction and Matching automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") automs_hpic_pos.find_features(min_intensity=20000, max_items=100000) automs_hpic_pos.match_features() \"\"\" # Match features with corresponding MS/MS spectra automs_hpic_pos.match_features_with_ms2() # Search a library for metabolite annotation based on the feature table automs_hpic_pos.search_library(\"Library/references_spectrums_positive.pickle\") Parameters : match_features_with_ms2 mz_tol (float): The m/z tolerance for matching features with spectra. Default is 0.01. rt_tol (float): The retention time tolerance for matching features with spectra. Default is 15. search_library lib_path (str): The path to the library file. method (str): The method for library search. Default is 'entropy'. ms1_da (float): The m/z tolerance for matching MS1 masses. Default is 0.01. ms2_da (float): The m/z tolerance for matching MS2 masses. Default is 0.05. threshold (float): The annotation confidence threshold. Default is 0.5. In this example, the code creates an AutoMSData object with the ion mode set to 'positive'. The data files are then loaded from the specified directory. Features are found in the loaded data using the specified parameters. Feature matching is performed, followed by feature matching with MS2 spectra. Finally, the feature annotation step is carried out using a library stored in the specified pickle file (\"Library/references_spectrums_positive.pickle\"). Supported similarity method : \"entropy\": Entropy distance \"unweighted_entropy\": Unweighted entropy distance \"euclidean\": Euclidean distance \"manhattan\": Manhattan distance \"chebyshev\": Chebyshev distance \"squared_euclidean\": Squared Euclidean distance \"fidelity\": Fidelity distance \"matusita\": Matusita distance \"squared_chord\": Squared-chord distance \"bhattacharya_1\": Bhattacharya 1 distance \"bhattacharya_2\": Bhattacharya 2 distance \"harmonic_mean\": Harmonic mean distance \"probabilistic_symmetric_chi_squared\": Probabilistic symmetric \u03c72 distance \"ruzicka\": Ruzicka distance \"roberts\": Roberts distance \"intersection\": Intersection distance \"motyka\": Motyka distance \"canberra\": Canberra distance \"baroni_urbani_buser\": Baroni-Urbani-Buser distance \"penrose_size\": Penrose size distance \"mean_character\": Mean character distance \"lorentzian\": Lorentzian distance \"penrose_shape\": Penrose shape distance \"clark\": Clark distance \"hellinger\": Hellinger distance \"whittaker_index_of_association\": Whittaker index of association distance \"symmetric_chi_squared\": Symmetric \u03c72 distance \"pearson_correlation\": Pearson/Spearman Correlation Coefficient \"improved_similarity\": Improved Similarity \"absolute_value\": Absolute Value Distance \"dot_product\": Dot-Product (cosine) \"dot_product_reverse\": Reverse dot-Product (cosine) \"spectral_contrast_angle\": Spectral Contrast Angle \"wave_hedges\": Wave Hedges distance \"cosine\": Cosine distance \"jaccard\": Jaccard distance \"dice\": Dice distance \"inner_product\": Inner Product distance \"divergence\": Divergence distance \"avg_l\": Avg (L1, L\u221e) distance \"vicis_symmetric_chi_squared_3\": Vicis-Symmetric \u03c72 3 distance \"ms_for_id_v1\": MSforID distance version 1 \"ms_for_id\": MSforID distance \"weighted_dot_product\": Weighted dot product distance\"","title":"Annotation with Library Search"},{"location":"feature_annotation/#how-to-build-a-library","text":"library should be stored in the specified pickle file, which is a list of matchms::Spectrum object. Here's an example code snippet of how to build library with GNPS data. GNPS data can be downloand at url import os import pickle import numpy as np from tqdm import tqdm from matchms.importing import load_from_mgf # Setting the path to the data directory path_data = os.path.join('D:/All_MSDatabase/GNPS_all') # Creating the full path to the MGF file filename = os.path.join(path_data, 'ALL_GNPS.mgf') # Loading spectrums from the MGF file using the 'load_from_mgf' function and creating a list of spectrums spectrums = [s for s in tqdm(load_from_mgf(filename))] from matchms.filtering import default_filters # Importing a function from the 'matchms.filtering' module from matchms.filtering import add_parent_mass, derive_adduct_from_name # Importing functions from the 'matchms.filtering' module # Defining a function to apply filters to a spectrum def apply_filters(s): s = default_filters(s) # Applying default filters to the spectrum s = derive_adduct_from_name(s) # Deriving the adduct from the spectrum's name s = add_parent_mass(s, estimate_from_adduct=True) # Adding the parent mass to the spectrum return s # Applying filters to the spectrums and creating a new list of filtered spectrums spectrums = [apply_filters(s) for s in tqdm(spectrums) if s is not None] # Saving the filtered spectrums as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) from matchms.filtering import harmonize_undefined_inchikey, harmonize_undefined_inchi, harmonize_undefined_smiles # Importing functions from the 'matchms.filtering' module from matchms.filtering import repair_inchi_inchikey_smiles # Importing a function from the 'matchms.filtering' module # Defining a function to clean the metadata of a spectrum def clean_metadata(s): s = harmonize_undefined_inchikey(s) # Harmonizing undefined InChI keys in the spectrum s = harmonize_undefined_inchi(s) # Harmonizing undefined InChI in the spectrum s = harmonize_undefined_smiles(s) # Harmonizing undefined SMILES in the spectrum s = repair_inchi_inchikey_smiles(s) # Repairing InChI, InChI key, and SMILES in the spectrum return s # Cleaning the metadata of the spectrums and creating a new list of spectrums with cleaned metadata spectrums = [clean_metadata(s) for s in tqdm(spectrums) if s is not None] # Saving the spectrums with cleaned metadata as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) from matchms.filtering import derive_inchi_from_smiles, derive_smiles_from_inchi # Importing functions from the 'matchms.filtering' module from matchms.filtering import derive_inchikey_from_inchi # Importing a function from the 'matchms.filtering' module # Defining a function to further clean the metadata of a spectrum def clean_metadata2(s): s = derive_inchi_from_smiles(s) # Deriving InChI from SMILES in the spectrum s = derive_smiles_from_inchi(s) # Deriving SMILES from InChI in the spectrum s = derive_inchikey_from_inchi(s) # Deriving InChI key from InChI in the spectrum return s # Further cleaning the metadata of the spectrums and creating a new list of spectrums with further cleaned metadata spectrums = [clean_metadata2(s) for s in tqdm(spectrums) if s is not None] # Saving the spectrums with further cleaned metadata as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) # Looping over each spectrum and modifying the compound name for spectrum in tqdm(spectrums): name_original = spectrum.get(\"compound_name\") # Getting the original compound name from the spectrum name = name_original.replace(\"F dial M\", \"\") # Removing \"F dial M\" from the compound name # Remove last word if likely not correct if name.split(\" \")[-1] in [\"M\", \"M?\", \"?\", \"M+2H/2\", \"MS34+Na\", \"M]\", \"Cat+M]\", \"Unk\", \"--\"]: name = \" \".join(name.split(\" \")[:-1]).strip() # Removing the last word from the compound name if name != name_original: print(f\"Changed compound name from {name_original} to {name}.\") # Printing the changed compound name spectrum.set(\"compound_name\", name) # Setting the modified compound name in the spectrum # Looping over each spectrum and modifying the ion mode for spec in spectrums: if spec.get(\"adduct\") in ['[M+CH3COO]-/[M-CH3]-', '[M-H]-/[M-Ser]-', '[M-CH3]-']: if spec.get(\"ionmode\") != \"negative\": spec.set(\"ionmode\", \"negative\") # Setting the ion mode to \"negative\" if specific adducts are present from matchms.filtering import normalize_intensities # Importing a function from the 'matchms.filtering' module from matchms.filtering import require_minimum_number_of_peaks # Importing a function from the 'matchms.filtering' module from matchms.filtering import select_by_mz # Importing a function from the 'matchms.filtering' module # Defining a function to post-process a spectrum def post_process(s): s = normalize_intensities(s) # Normalizing the intensities of the spectrum s = select_by_mz(s, mz_from=10.0, mz_to=1000) # Selecting peaks within a specific m/z range s = require_minimum_number_of_peaks(s, n_required=5) # Requiring a minimum number of peaks in the spectrum return s # Post-processing the spectrums and creating a new list of post-processed spectrums spectrums = [post_process(s) for s in tqdm(spectrums)] # Saving the post-processed spectrums as a NumPy array np.save(os.path.join(path_data, 'preprocessed_spectrums.npy'), spectrums) spectrums = [s for s in spectrums if s is not None] # Filtering out any None values from the spectrums spectrums_positive = [] # Creating an empty list for positive ion mode spectrums spectrums_negative = [] # Creating an empty list for negative ion mode spectrums # Looping over each spectrum and categorizing them based on ion mode for i, spec in enumerate(spectrums): if spec.get(\"ionmode\") == \"positive\": spectrums_positive.append(spec) # Adding the spectrum to the positive ion mode list elif spec.get(\"ionmode\") == \"negative\": spectrums_negative.append(spec) # Adding the spectrum to the negative ion mode list else: print(f\"No ionmode found for spectrum {i} ({spec.get('ionmode')})\") # Printing a message if no ion mode is found # Pickling the negative ion mode spectrums and saving them as a pickle file pickle.dump(spectrums_negative, open(os.path.join(path_data, 'ALL_GNPS_220601_negative_cleaned.pickle'), \"wb\")) # Pickling the positive ion mode spectrums and saving them as a pickle file pickle.dump(spectrums_positive, open(os.path.join(path_data, 'ALL_GNPS_220601_positive_cleaned.pickle'), \"wb\"))","title":"How to Build a Library"},{"location":"feature_annotation/#annotation-with-deepmass","text":"comming soon","title":"Annotation with DeepMASS"},{"location":"feature_extraction/","text":"Extraction of Features from Raw Data Metabolomics is a rapidly growing field that aims to comprehensively study and analyze the small molecule metabolites present in biological samples. Mass spectrometry (MS) is a widely used technique in metabolomics due to its high sensitivity, resolution, and ability to detect a wide range of metabolites. Feature Extraction with AutoMS AutoMS provides HPIC as the default algorithm of feature extraction. Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) was utilized to extract Potential Ion Channels (PICs) from LC to MS data sets. Metabolites typically produce densely populated and continuous ions in both the m/z (mass-to-charge ratio) and elution time dimensions. By employing HDBSCAN, ions belonging to the same metabolite can be grouped together, eliminating the need for defining a specific m/z tolerance. Here's an example code snippet: from AutoMS import automs # Instantiate AutoMS for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') # Load data files automs_hpic_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") # Perform feature extraction automs_hpic_pos.find_features(min_intensity=20000, max_items=100000) Parameters : AutoMSData ion_mode (str): The ionization mode. Default is 'positive'. load_files data_path (str): The path to the directory containing the data files. find_features min_intensity (int): The minimum intensity threshold for peak detection. Suggest: Q-TOF 1000-3000; Orbitrap 10000-30000. mass_inv (int): The inverse of mass tolerance for clustering ions of the same metabolite. Default is 1. rt_inv (int): The inverse of retention time tolerance for clustering ions of the same metabolite. Default is 30. min_snr (int): The minimum signal-to-noise ratio threshold for peak detection. Default is 3. max_items (int): The maximum number of ion traces to process. Default is 50000. Evaluating Peak Quality of Features AutoMS employs a deep learning-based denoising autoencoder to grasp the common characteristics of chromatographic peaks, and predict noisededucted peaks from the original peak profiles. By comparing the difference before and after processed, it scores the peak quality continuously and precisely. Here's an example code snippet: automs_hpic_pos.evaluate_features() Matching Features Across Samples Feature matching is a crucial step in the analysis of mass spectrometry-based metabolomics data. It involves comparing and aligning features detected across multiple samples or datasets to identify matching features and establish their correspondence. In metabolomics, features typically represent specific molecular entities such as metabolites. These features are characterized by their mass-to-charge ratio (m/z) and retention time (RT), which are important parameters for their identification and quantification. Feature matching aims to find corresponding features across different samples or datasets by comparing their m/z and RT values. This process allows for the identification of consistent features that represent the same metabolite across various experimental conditions or biological samples. Here's an example code snippet: automs_hpic_pos.match_features(method = 'simple', mz_tol = 0.01, rt_tol = 20, min_frac = 0.5) Parameters : match_features method (str): The feature matching method to use. Default is 'simple' (only support at present). mz_tol (float): The mass-to-charge ratio tolerance for feature matching. Default is 0.01. rt_tol (float): The retention time tolerance for feature matching. Default is 20 (seconds). min_frac (float): The minimum fraction of samples that should have a feature for it to be considered. Default is 0.5. Load Feature Extraction Results of MS-DIAL MS-DIAL is a powerful software tool designed for mass spectrometry-based metabolomics data analysis. It offers a comprehensive set of functionalities, including feature extraction, alignment, and quantification of metabolites. AutoMS can load the feature extraction results of MS-DIAL directly. By loading the MS-DIAL feature extraction results into the AutoMS software, you can access and further analyze the extracted features and their associated information for downstream processing and interpretation. Here's an example code snippet: from AutoMS import automs # Instantiate AutoMS for positive ion mode automs_msdial_pos = automs.AutoMS(ion_mode='positive') # Load data files automs_msdial_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") # Load MS-DIAL feature extraction results automs_msdial_pos.load_msdial(\"E:/Data/Guanghuoxiang/MSDIAL_processing/Positive_Height_0_2023423819.txt\") Parameters : load_msdial: msdial_path (str): The path to the MS-DIAL feature extraction result file.","title":"Feature Extraction"},{"location":"feature_extraction/#extraction-of-features-from-raw-data","text":"Metabolomics is a rapidly growing field that aims to comprehensively study and analyze the small molecule metabolites present in biological samples. Mass spectrometry (MS) is a widely used technique in metabolomics due to its high sensitivity, resolution, and ability to detect a wide range of metabolites.","title":"Extraction of Features from Raw Data"},{"location":"feature_extraction/#feature-extraction-with-automs","text":"AutoMS provides HPIC as the default algorithm of feature extraction. Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) was utilized to extract Potential Ion Channels (PICs) from LC to MS data sets. Metabolites typically produce densely populated and continuous ions in both the m/z (mass-to-charge ratio) and elution time dimensions. By employing HDBSCAN, ions belonging to the same metabolite can be grouped together, eliminating the need for defining a specific m/z tolerance. Here's an example code snippet: from AutoMS import automs # Instantiate AutoMS for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') # Load data files automs_hpic_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") # Perform feature extraction automs_hpic_pos.find_features(min_intensity=20000, max_items=100000) Parameters : AutoMSData ion_mode (str): The ionization mode. Default is 'positive'. load_files data_path (str): The path to the directory containing the data files. find_features min_intensity (int): The minimum intensity threshold for peak detection. Suggest: Q-TOF 1000-3000; Orbitrap 10000-30000. mass_inv (int): The inverse of mass tolerance for clustering ions of the same metabolite. Default is 1. rt_inv (int): The inverse of retention time tolerance for clustering ions of the same metabolite. Default is 30. min_snr (int): The minimum signal-to-noise ratio threshold for peak detection. Default is 3. max_items (int): The maximum number of ion traces to process. Default is 50000.","title":"Feature Extraction with AutoMS"},{"location":"feature_extraction/#evaluating-peak-quality-of-features","text":"AutoMS employs a deep learning-based denoising autoencoder to grasp the common characteristics of chromatographic peaks, and predict noisededucted peaks from the original peak profiles. By comparing the difference before and after processed, it scores the peak quality continuously and precisely. Here's an example code snippet: automs_hpic_pos.evaluate_features()","title":"Evaluating Peak Quality of Features"},{"location":"feature_extraction/#matching-features-across-samples","text":"Feature matching is a crucial step in the analysis of mass spectrometry-based metabolomics data. It involves comparing and aligning features detected across multiple samples or datasets to identify matching features and establish their correspondence. In metabolomics, features typically represent specific molecular entities such as metabolites. These features are characterized by their mass-to-charge ratio (m/z) and retention time (RT), which are important parameters for their identification and quantification. Feature matching aims to find corresponding features across different samples or datasets by comparing their m/z and RT values. This process allows for the identification of consistent features that represent the same metabolite across various experimental conditions or biological samples. Here's an example code snippet: automs_hpic_pos.match_features(method = 'simple', mz_tol = 0.01, rt_tol = 20, min_frac = 0.5) Parameters : match_features method (str): The feature matching method to use. Default is 'simple' (only support at present). mz_tol (float): The mass-to-charge ratio tolerance for feature matching. Default is 0.01. rt_tol (float): The retention time tolerance for feature matching. Default is 20 (seconds). min_frac (float): The minimum fraction of samples that should have a feature for it to be considered. Default is 0.5.","title":"Matching Features Across Samples"},{"location":"feature_extraction/#load-feature-extraction-results-of-ms-dial","text":"MS-DIAL is a powerful software tool designed for mass spectrometry-based metabolomics data analysis. It offers a comprehensive set of functionalities, including feature extraction, alignment, and quantification of metabolites. AutoMS can load the feature extraction results of MS-DIAL directly. By loading the MS-DIAL feature extraction results into the AutoMS software, you can access and further analyze the extracted features and their associated information for downstream processing and interpretation. Here's an example code snippet: from AutoMS import automs # Instantiate AutoMS for positive ion mode automs_msdial_pos = automs.AutoMS(ion_mode='positive') # Load data files automs_msdial_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") # Load MS-DIAL feature extraction results automs_msdial_pos.load_msdial(\"E:/Data/Guanghuoxiang/MSDIAL_processing/Positive_Height_0_2023423819.txt\") Parameters : load_msdial: msdial_path (str): The path to the MS-DIAL feature extraction result file.","title":"Load Feature Extraction Results of MS-DIAL"},{"location":"getting_started/","text":"Getting Started with the AutoMS following example code demonstrates the usage of the AutoMS software for feature extraction, feature matching, library searching, and data analysis in mass spectrometry-based metabolomics. The code showcases various steps involved in the processing and analysis of metabolomics data using the AutoMS package. from AutoMS import automs # Feature extraction for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") automs_hpic_pos.find_features(min_intensity=20000, max_items=100000) # Feature matching for positive ion mode automs_hpic_pos.match_features() automs_hpic_pos.match_features_with_ms2() # Library searching for positive ion mode automs_hpic_pos.search_library(\"Library/references_spectrums_positive.pickle\") # Save project for positive ion mode automs_hpic_pos.save_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") # Feature extraction for negative ion mode automs_hpic_neg = automs.AutoMSData(ion_mode='negative') automs_hpic_neg.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/NEG\") automs_hpic_neg.find_features(min_intensity=20000, max_items=100000) # Feature matching for negative ion mode automs_hpic_neg.match_features() automs_hpic_neg.match_features_with_ms2() # Library searching for negative ion mode automs_hpic_neg.search_library(\"Library/references_spectrums_negative.pickle\") # Save project for negative ion mode automs_hpic_neg.save_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_negative.project\") # Group information qc_samples = ['QC-{}'.format(i) for i in range(1,6)] group_info = { 'QC': ['QC-{}'.format(i) for i in range(1,6)], 'PX_L': ['PX-L-{}'.format(i) for i in range(1,7)], 'PX_S': ['PX-S-{}'.format(i) for i in range(1,7)], 'ZX_L': ['ZX-L-{}'.format(i) for i in range(1,7)], 'ZX_S': ['ZX-S-{}'.format(i) for i in range(1,7)], 'NX_L': ['NX-L-{}'.format(i) for i in range(1,7)], 'NX_S': ['NX-S-{}'.format(i) for i in range(1,7)] } # Load and export features for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") automs_hpic_pos = automs_hpic_pos.export_features() # Load and export features for negative ion mode automs_hpic_neg = automs.AutoMSData(ion_mode='negative') automs_hpic_neg.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_negative.project\") automs_hpic_neg = automs_hpic_neg.export_features() # Merge positive and negative features automs_hpic_feat = automs.AutoMSFeature() automs_hpic_feat.append_feature_table(automs_hpic_pos) automs_hpic_feat.append_feature_table(automs_hpic_neg) # Preprocessing and refining annotated table automs_hpic_feat.preprocessing( impute_method='KNN', outlier_threshold=3, rsd_threshold=0.3, min_frac=0.5, qc_samples=qc_samples, group_info=group_info ) automs_hpic_feat.refine_annotated_table() # Perform dimensional reduction and analysis automs_hpic_feat.perform_dimensional_reduction( group_info=group_info, method='PCA', annotated_only=False ) automs_hpic_feat.perform_PLSDA(group_info=group_info, n_components=3) automs_hpic_feat.perform_RandomForest(group_info=group_info) # Select biomarkers and generate heatmap automs_hpic_feat.select_biomarker( criterion={'PLS_VIP': ['>', 1.2], 'RF_VIP': ['>', 0.15]}, combination='intersection' ) automs_hpic_feat.perform_heatmap( group_info=group_info, hide_xticks=False, hide_ytick=False ) The provided code demonstrates the usage of AutoMS for feature extraction, matching, library searching, and subsequent data analysis steps. It covers both positive and negative ion modes, showcases project loading and saving, and includes preprocessing, dimensional reduction, and biomarker selection. These steps enable the processing and analysis of mass spectrometry-based metabolomics data using the AutoMS software.","title":"Getting started"},{"location":"getting_started/#getting-started-with-the-automs","text":"following example code demonstrates the usage of the AutoMS software for feature extraction, feature matching, library searching, and data analysis in mass spectrometry-based metabolomics. The code showcases various steps involved in the processing and analysis of metabolomics data using the AutoMS package. from AutoMS import automs # Feature extraction for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/POS\") automs_hpic_pos.find_features(min_intensity=20000, max_items=100000) # Feature matching for positive ion mode automs_hpic_pos.match_features() automs_hpic_pos.match_features_with_ms2() # Library searching for positive ion mode automs_hpic_pos.search_library(\"Library/references_spectrums_positive.pickle\") # Save project for positive ion mode automs_hpic_pos.save_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") # Feature extraction for negative ion mode automs_hpic_neg = automs.AutoMSData(ion_mode='negative') automs_hpic_neg.load_files(\"E:/Data/Guanghuoxiang/Convert_files_mzML/NEG\") automs_hpic_neg.find_features(min_intensity=20000, max_items=100000) # Feature matching for negative ion mode automs_hpic_neg.match_features() automs_hpic_neg.match_features_with_ms2() # Library searching for negative ion mode automs_hpic_neg.search_library(\"Library/references_spectrums_negative.pickle\") # Save project for negative ion mode automs_hpic_neg.save_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_negative.project\") # Group information qc_samples = ['QC-{}'.format(i) for i in range(1,6)] group_info = { 'QC': ['QC-{}'.format(i) for i in range(1,6)], 'PX_L': ['PX-L-{}'.format(i) for i in range(1,7)], 'PX_S': ['PX-S-{}'.format(i) for i in range(1,7)], 'ZX_L': ['ZX-L-{}'.format(i) for i in range(1,7)], 'ZX_S': ['ZX-S-{}'.format(i) for i in range(1,7)], 'NX_L': ['NX-L-{}'.format(i) for i in range(1,7)], 'NX_S': ['NX-S-{}'.format(i) for i in range(1,7)] } # Load and export features for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") automs_hpic_pos = automs_hpic_pos.export_features() # Load and export features for negative ion mode automs_hpic_neg = automs.AutoMSData(ion_mode='negative') automs_hpic_neg.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_negative.project\") automs_hpic_neg = automs_hpic_neg.export_features() # Merge positive and negative features automs_hpic_feat = automs.AutoMSFeature() automs_hpic_feat.append_feature_table(automs_hpic_pos) automs_hpic_feat.append_feature_table(automs_hpic_neg) # Preprocessing and refining annotated table automs_hpic_feat.preprocessing( impute_method='KNN', outlier_threshold=3, rsd_threshold=0.3, min_frac=0.5, qc_samples=qc_samples, group_info=group_info ) automs_hpic_feat.refine_annotated_table() # Perform dimensional reduction and analysis automs_hpic_feat.perform_dimensional_reduction( group_info=group_info, method='PCA', annotated_only=False ) automs_hpic_feat.perform_PLSDA(group_info=group_info, n_components=3) automs_hpic_feat.perform_RandomForest(group_info=group_info) # Select biomarkers and generate heatmap automs_hpic_feat.select_biomarker( criterion={'PLS_VIP': ['>', 1.2], 'RF_VIP': ['>', 0.15]}, combination='intersection' ) automs_hpic_feat.perform_heatmap( group_info=group_info, hide_xticks=False, hide_ytick=False ) The provided code demonstrates the usage of AutoMS for feature extraction, matching, library searching, and subsequent data analysis steps. It covers both positive and negative ion modes, showcases project loading and saving, and includes preprocessing, dimensional reduction, and biomarker selection. These steps enable the processing and analysis of mass spectrometry-based metabolomics data using the AutoMS software.","title":"Getting Started with the AutoMS"},{"location":"install/","text":"Installation Guide Below the workflow of installation is presented. Install the dependencies first, Then, install AutoMS. Install Dependencies Please follow the steps: Step 1: Install Anaconda Visit the Anaconda website, Download the appropriate installer for your operating system, and run the installer and follow the on-screen instructions to complete the installation. Step 2: Create a new environment Open the command prompt, and run the following command to create a new environment with the specific Python version: conda create --name automs python=3.8.16 Activate the newly created environment by running the following command: conda activate automs Step 3: Install dependencies Use conda install to install the following packages: conda install -c conda-forge hdbscan==0.8.29 Install AutoMS You can either install from GitHub or PyPI: Install from GitHub: Running the following command: pip install git+https://github.com/hcji/AutoMS2.git Install from PyPI Comming soon...","title":"Installation"},{"location":"install/#installation-guide","text":"Below the workflow of installation is presented. Install the dependencies first, Then, install AutoMS.","title":"Installation Guide"},{"location":"install/#install-dependencies","text":"Please follow the steps:","title":"Install Dependencies"},{"location":"install/#step-1-install-anaconda","text":"Visit the Anaconda website, Download the appropriate installer for your operating system, and run the installer and follow the on-screen instructions to complete the installation.","title":"Step 1: Install Anaconda"},{"location":"install/#step-2-create-a-new-environment","text":"Open the command prompt, and run the following command to create a new environment with the specific Python version: conda create --name automs python=3.8.16 Activate the newly created environment by running the following command: conda activate automs","title":"Step 2: Create a new environment"},{"location":"install/#step-3-install-dependencies","text":"Use conda install to install the following packages: conda install -c conda-forge hdbscan==0.8.29","title":"Step 3: Install dependencies"},{"location":"install/#install-automs","text":"You can either install from GitHub or PyPI:","title":"Install AutoMS"},{"location":"install/#install-from-github","text":"Running the following command: pip install git+https://github.com/hcji/AutoMS2.git","title":"Install from GitHub:"},{"location":"install/#install-from-pypi","text":"Comming soon...","title":"Install from PyPI"},{"location":"library/","text":"MS/MS Library This is a list of processed MS/MS library, which can be directly used for AutoMS spectral searching. Most of them are collected from public source. ALL GNPS without Propagated Download Link : comming soon... Citation : comming soon...","title":"MS/MS Library"},{"location":"library/#msms-library","text":"This is a list of processed MS/MS library, which can be directly used for AutoMS spectral searching. Most of them are collected from public source.","title":"MS/MS Library"},{"location":"library/#all-gnps-without-propagated","text":"Download Link : comming soon... Citation : comming soon...","title":"ALL GNPS without Propagated"},{"location":"ms_convert/","text":"Converting MS Data Files to mzML Mass spectrometry (MS) data files acquired from different vendors often come in proprietary formats that are not compatible with standard analysis tools. AutoMS support the mzML format only, one widely used approach is to convert the vendor-specific data files into the mzML format, which is a standardized file format for MS data. To convert MS data files into mzML using msconvert, follow the steps outlined below: Step 1: Install ProteoWizard Before using msconvert, you need to install the ProteoWizard software suite. Follow these instructions to install it: Visit the ProteoWizard website: ProteoWizard Website . Download the appropriate installer for your operating system. Run the installer and follow the on-screen instructions to complete the installation. Step 2: Open a Command Prompt or Terminal Once ProteoWizard is installed, open a command prompt (Windows) or terminal (macOS/Linux) to access the msconvert tool. Step 3: Convert MS Data to mzML To convert the MS data file to mzML, use the following command: msconvert <input_file> -o <output_directory> --mzML Replace input_file with the path to the vendor-specific MS data file that you want to convert. Specify the output_directory where you want to save the converted mzML file. For example, to convert a Thermo RAW file named sample.raw to mzML and save it in the current directory, use the command: msconvert sample.raw -o . --mzML Step 4: Additional Conversion Options msconvert provides additional options to customize the conversion process. Some common options include: --filter: Apply data filtering during conversion. --mz5: Convert the data to the mz5 format. --gzip: Compress the output mzML file using gzip. --32-bit: Convert the data to 32-bit floating-point format. Refer to the msconvert documentation for a full list of available options and their usage.","title":"Prepare MS Files"},{"location":"ms_convert/#converting-ms-data-files-to-mzml","text":"Mass spectrometry (MS) data files acquired from different vendors often come in proprietary formats that are not compatible with standard analysis tools. AutoMS support the mzML format only, one widely used approach is to convert the vendor-specific data files into the mzML format, which is a standardized file format for MS data. To convert MS data files into mzML using msconvert, follow the steps outlined below:","title":"Converting MS Data Files to mzML"},{"location":"ms_convert/#step-1-install-proteowizard","text":"Before using msconvert, you need to install the ProteoWizard software suite. Follow these instructions to install it: Visit the ProteoWizard website: ProteoWizard Website . Download the appropriate installer for your operating system. Run the installer and follow the on-screen instructions to complete the installation.","title":"Step 1: Install ProteoWizard"},{"location":"ms_convert/#step-2-open-a-command-prompt-or-terminal","text":"Once ProteoWizard is installed, open a command prompt (Windows) or terminal (macOS/Linux) to access the msconvert tool.","title":"Step 2: Open a Command Prompt or Terminal"},{"location":"ms_convert/#step-3-convert-ms-data-to-mzml","text":"To convert the MS data file to mzML, use the following command: msconvert <input_file> -o <output_directory> --mzML Replace input_file with the path to the vendor-specific MS data file that you want to convert. Specify the output_directory where you want to save the converted mzML file. For example, to convert a Thermo RAW file named sample.raw to mzML and save it in the current directory, use the command: msconvert sample.raw -o . --mzML","title":"Step 3: Convert MS Data to mzML"},{"location":"ms_convert/#step-4-additional-conversion-options","text":"msconvert provides additional options to customize the conversion process. Some common options include: --filter: Apply data filtering during conversion. --mz5: Convert the data to the mz5 format. --gzip: Compress the output mzML file using gzip. --32-bit: Convert the data to 32-bit floating-point format. Refer to the msconvert documentation for a full list of available options and their usage.","title":"Step 4: Additional Conversion Options"},{"location":"network_analysis/","text":"Molecular Network Analysis Molecular networks are powerful tools used in metabolomics to analyze and visualize the relationships between metabolites based on their structural similarities or chemical associations. These networks provide insights into the connectivity and interactions among metabolites, helping to uncover potential pathways, functional modules, and biological relationships. In a molecular network, nodes represent individual metabolites, and edges represent connections between metabolites based on their chemical similarity or shared metabolic transformations. The construction of molecular networks involves analyzing data such as mass spectrometry-based metabolite profiles or chemical databases to identify structural similarities or functional relationships between metabolites. AutoMS provides dynamic graph of global network, including all annotated metabolites, highlighting the biomarkers if they have been selected by statistical analysis. In this plot, each metabolite is a single point. It also provides sub-network if a specific compound need to be focused on. In this plot, metabolites shown as chemical images, accompanied with chemical names and relative concentration relationships among groups. Here's an example code snippet: # after Feature Detection, Metabolite Annotation and Statistical Analysis automs_hpic_feat.select_biomarker(criterion = {'PLS_VIP': ['>', 1.2]}) automs_hpic_feat.perform_molecular_network(threshold = 0.5) # or automs_hpic_feat.perform_molecular_network(threshold = 0.5, target_compound = 'Stachyose', group_info = group_info) Parameters : perform_molecular_network threshold (float): The threshold value of similarity for creating the network. Default is 0.5. target_compound (str): The target compound to focus on in the network. Default is None. group_info (dict): The dictionary specifying group information for sample grouping.","title":"Network Analysis"},{"location":"network_analysis/#molecular-network-analysis","text":"Molecular networks are powerful tools used in metabolomics to analyze and visualize the relationships between metabolites based on their structural similarities or chemical associations. These networks provide insights into the connectivity and interactions among metabolites, helping to uncover potential pathways, functional modules, and biological relationships. In a molecular network, nodes represent individual metabolites, and edges represent connections between metabolites based on their chemical similarity or shared metabolic transformations. The construction of molecular networks involves analyzing data such as mass spectrometry-based metabolite profiles or chemical databases to identify structural similarities or functional relationships between metabolites. AutoMS provides dynamic graph of global network, including all annotated metabolites, highlighting the biomarkers if they have been selected by statistical analysis. In this plot, each metabolite is a single point. It also provides sub-network if a specific compound need to be focused on. In this plot, metabolites shown as chemical images, accompanied with chemical names and relative concentration relationships among groups. Here's an example code snippet: # after Feature Detection, Metabolite Annotation and Statistical Analysis automs_hpic_feat.select_biomarker(criterion = {'PLS_VIP': ['>', 1.2]}) automs_hpic_feat.perform_molecular_network(threshold = 0.5) # or automs_hpic_feat.perform_molecular_network(threshold = 0.5, target_compound = 'Stachyose', group_info = group_info) Parameters : perform_molecular_network threshold (float): The threshold value of similarity for creating the network. Default is 0.5. target_compound (str): The target compound to focus on in the network. Default is None. group_info (dict): The dictionary specifying group information for sample grouping.","title":"Molecular Network Analysis"},{"location":"statistics/","text":"Statistical Analysis In metabolomics, the statistical analysis of features plays a crucial role in extracting meaningful insights from complex datasets. It aims to understand the metabolic changes and patterns associated with various physiological conditions, diseases, and environmental factors. AutoMS provides the key aspects of statistical analysis in metabolomics. Statistical analysis in AutoMS is performed on AutoMSFeature class, which is obtained from export_features of AutoMSData class. Here's an example code snippet: automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") automs_hpic_pos = automs_hpic_pos.export_features() Here, automs_hpic_pos is obtained and saved followed the feature_extraction steps. Data Combination Data combination in metabolomics refers to the integration of metabolomics datasets obtained from different ionization modes, such as positive and negative modes. Combining data from multiple ionization modes can provide a more comprehensive view of the metabolome and improve the coverage and reliability of metabolite identification. AutoMS achieves this by append_feature_table function, Here's an example code snippet: # Load and export features for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") automs_hpic_pos = automs_hpic_pos.export_features() # Load and export features for negative ion mode automs_hpic_neg = automs.AutoMSData(ion_mode='negative') automs_hpic_neg.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_negative.project\") automs_hpic_neg = automs_hpic_neg.export_features() # Merge positive and negative features automs_hpic_feat = automs.AutoMSFeature() automs_hpic_feat.append_feature_table(automs_hpic_pos) automs_hpic_feat.append_feature_table(automs_hpic_neg) Preprocessing Preprocessing involves various steps to transform raw metabolomics data into a suitable format for analysis. It aims to reduce noise, correct systematic biases, and normalize the data. The preprocessing steps include: Data cleaning: Removing missing values and outliers. Imputation: Estimating missing values based on statistical methods. Data normalization: Scaling the data to account for differences in sample concentration or instrument response. Correlation Evaluation: Calculate correlations between QC samples, evaluating the experimental consistency. Here's an example code snippet: # Information of samples qc_samples = ['QC-{}'.format(i) for i in range(1,6)] group_info = { 'QC': ['QC-{}'.format(i) for i in range(1,6)], # QC group 'PX_L': ['PX-L-{}'.format(i) for i in range(1,7)], # Leaf of PX 'PX_S': ['PX-S-{}'.format(i) for i in range(1,7)], # Stem of PX 'ZX_L': ['ZX-L-{}'.format(i) for i in range(1,7)], # Leaf of ZX 'ZX_S': ['ZX-S-{}'.format(i) for i in range(1,7)], # Stem of ZX 'NX_L': ['NX-L-{}'.format(i) for i in range(1,7)], # Leaf of NX 'NX_S': ['NX-S-{}'.format(i) for i in range(1,7)] # Stem of NX } # Preprocessing automs_hpic_feat.preprocessing( impute_method='KNN', outlier_threshold=3, rsd_threshold=0.3, min_frac=0.5, qc_samples=qc_samples, group_info=group_info ) # Refine annotated table and remove repetitive annotations automs_hpic_feat.refine_annotated_table() Parameters : preprocessing impute_method (str): The imputation method to use. outlier_threshold (float): The threshold for outlier removal. rsd_threshold (float): The threshold for relative standard deviation (RSD) filtering. min_frac (float): The minimum fraction of non-missing values required for a feature to be retained. qc_samples (list): The list of QC sample names. group_info (dict): The dictionary containing group information for sample grouping. args: Additional keyword arguments for the preprocessing method. Supported similarity method : 'Low value': The missing values are imputed with a low value. 'Mean': The mean imputation method replaces missing values with the mean value of the corresponding feature. 'Median': Similar to mean imputation, the median imputation method replaces missing values with the median value of the corresponding feature. 'KNN': K-nearest neighbors (KNN) imputation imputes missing values by considering the values of the k-nearest neighbors in the feature space. 'Iterative RF': Iterative Random Forest (RF) imputation is an iterative imputation method. It builds a random forest model to predict the missing values based on other features. 'Iterative BR': Iterative Bayesian Ridge (BR) imputation is another iterative imputation method. It uses a Bayesian Ridge regression model to estimate the missing values based on other features. 'Iterative SVR': Iterative Support Vector Regression (SVR) imputation is an iterative method that uses support vector regression to predict missing values. It builds a regression model using non-missing values as the training data and predicts the missing values. Dimensional Reduction Analysis Dimensionality reduction analysis is a technique used in machine learning and data analysis to reduce the dimensionality of a dataset while preserving its important structures and patterns. It aims to overcome the curse of dimensionality by transforming high-dimensional data into a lower-dimensional space. Principal Component Analysis (PCA) : PCA is a widely used linear dimensionality reduction technique. It identifies the directions in the data that capture the maximum variance, known as principal components. These components form a new orthogonal coordinate system, where the data can be represented with fewer dimensions while retaining most of the original information. t-Distributed Stochastic Neighbor Embedding (t-SNE) : t-SNE is a nonlinear dimensionality reduction method that emphasizes the preservation of local structure and relationships between data points. It maps high-dimensional data to a lower-dimensional space by modeling the similarity between data points in the original space and the lower-dimensional space. t-SNE is particularly useful for visualizing clusters and identifying patterns in complex datasets. Uniform Manifold Approximation and Projection (UMAP) : UMAP is a nonlinear dimensionality reduction algorithm that preserves both local and global structure. It constructs a high-dimensional graph representation of the data and optimizes a low-dimensional graph representation that captures the same topological structure. UMAP is known for its scalability and ability to preserve complex data relationships. Here's an example code snippet: automs_hpic_feat.perform_dimensional_reduction(group_info = group_info, method = 'PCA', annotated_only = True) automs_hpic_feat.perform_dimensional_reduction(group_info = group_info, method = 'tSNE', annotated_only = True) automs_hpic_feat.perform_dimensional_reduction(group_info = group_info, method = 'uMAP', annotated_only = True) Parameters : perform_dimensional_reduction group_info (dict): The dictionary containing group information for sample grouping. method (str): The dimensional reduction method to use (e.g., 'PCA', 'tSNE', 'uMAP'). annotated_only (bool): Whether to use only the annotated feature table for dimensional reduction. args: Additional keyword arguments for the dimensional reduction method. T-Test Analysis T-test analysis is a statistical method used to compare the means of two groups and determine if there is a significant difference between them. It is commonly used in hypothesis testing to assess whether the difference observed between two sample means is likely to occur due to random chance or if it represents a true difference in the population means. AutoMS conduct T-Test by perform_T_Test function. Multi test correlation is integrated, and volcano plot is carry out automatically. Here's an example code snippet: group_info = {'PX_L': ['PX-L-{}'.format(i) for i in range(1,7)], 'ZX_L': ['ZX-L-{}'.format(i) for i in range(1,7)]} automs_hpic_feat.perform_T_Test(group_info = group_info, , annotated_only = True, alpha=0.05, method='fdr_bh') Parameters : perform_T_Test group_info (dict): The dictionary specifying group information for sample grouping. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. alpha (float): significance level to apply. method (str): multiple testing correction method to apply. Multivariate Statistical Analysis The multivariate statistical analysis methods, including PLS-DA, RF, and Gradient Boosting, provide valuable tools for feature selection, classification, and predictive modeling in metabolomics research. They aid in understanding the underlying patterns and discriminating features in large and complex metabolomics datasets, facilitating biomarker discovery, sample classification, and interpretation of metabolite associations with different conditions or phenotypes. Partial Least Squares Discriminant Analysis (PLS-DA) : PLS-DA is a supervised multivariate technique commonly used in metabolomics to classify samples into predefined groups based on their metabolite profiles. It identifies the metabolites that contribute the most to the separation between groups and creates a predictive model. PLS-DA combines features of both principal component analysis (PCA) and linear regression to maximize the separation between groups while considering the relationship between metabolites and sample classes. Random Forest (RF) : RF is a machine learning algorithm widely applied in metabolomics for classification and feature selection. It constructs an ensemble of decision trees and combines their predictions to make accurate classifications. RF can handle high-dimensional data and identify the most important metabolites for classification, allowing for the interpretation of discriminatory features. Gradient Boosting : Gradient boosting is another machine learning technique commonly used in metabolomics, particularly with algorithms like XGBoost or LightGBM. Gradient boosting sequentially trains a series of weak models (usually decision trees) by focusing on the samples that were not well predicted by previous models. The weak models are then combined to create a strong predictive model that can accurately classify samples or predict their properties. Gradient boosting can handle complex relationships and capture non-linear patterns in metabolomics data. Here's an example code snippet: automs_hpic_feat.perform_PLSDA(group_info = group_info, n_components = 3, n_permutations = 1000, annotated_only = True, loo_test = True, permutation_test = True) automs_hpic_feat.perform_GradientBoost(group_info = group_info, annotated_only = True, loo_test = True, model = 'XGBoost', n_estimators = 500) automs_hpic_feat.perform_RandomForest(group_info = group_info, annotated_only = True, loo_test = True, n_estimators = 500, max_depth = 10) Parameters : perform_PLSDA group_info (dict): The dictionary specifying group information for sample grouping. n_components (int): The number of components to use. Default is 2. n_permutations (int): The number of permutations to perform for permutation test. Default is 1000. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. loo_test (bool): Flag indicating whether to perform leave-one-out test. Default is True. permutation_test (bool): Flag indicating whether to perform permutation test. Default is True. perform_GradientBoost model (str): The gradient boosting model to use ('XGBoost' or 'LightGBM'). Default is 'XGBoost'. group_info (dict): The dictionary specifying group information for sample grouping. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. loo_test (bool): Flag indicating whether to perform leave-one-out test. Default is True. args: Additional arguments to be passed to the Gradient Boosting analysis. perform_RandomForest group_info (dict): The dictionary specifying group information for sample grouping. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. loo_test (bool): Flag indicating whether to perform leave-one-out test. Default is True. args: Additional arguments to be passed to the Random Forest analysis. HeatMap of Biomarkers A heatmap of metabolite biomarkers is a graphical representation that visualizes the relative abundance or expression levels of metabolites across different samples or conditions. It provides a comprehensive overview of the patterns and trends in metabolite profiles, highlighting the metabolites that show significant differences or associations with specific groups or conditions. In a heatmap, each row represents a metabolite, and each column represents a sample or condition. The intensity of color or shading in each cell of the heatmap reflects the abundance or expression level of the corresponding metabolite in the respective sample or condition. Typically, a color scale is used, where higher values are represented by darker or brighter colors, and lower values are represented by lighter or muted colors. Here's an example code snippet: # This step should after perform T-Test analysis or/and multivariate statistical analysis automs_hpic_feat.select_biomarker(criterion = {'PLS_VIP': ['>', 1.5], 'RF_VIP': ['>', 0.2]}, combination = 'union') automs_hpic_feat.perform_heatmap(group_info = group_info, hide_xticks = False, hide_ytick = False) Parameters : select_biomarker criterion (dict): The dictionary specifying the criteria for biomarker selection. combination (str): The combination method for multiple criteria ('union' or 'intersection'). Default is 'union'. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. perform_heatmap biomarker_only (bool): Flag indicating whether to use only the biomarker table. Default is True. group_info (dict): The dictionary specifying group information for sample grouping. hide_xticks (bool): Flag indicating whether to hide the x-axis tick labels. Default is False. hide_ytick (bool): Flag indicating whether to hide the y-axis tick labels. Default is False.","title":"Statistical Analysis"},{"location":"statistics/#statistical-analysis","text":"In metabolomics, the statistical analysis of features plays a crucial role in extracting meaningful insights from complex datasets. It aims to understand the metabolic changes and patterns associated with various physiological conditions, diseases, and environmental factors. AutoMS provides the key aspects of statistical analysis in metabolomics. Statistical analysis in AutoMS is performed on AutoMSFeature class, which is obtained from export_features of AutoMSData class. Here's an example code snippet: automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") automs_hpic_pos = automs_hpic_pos.export_features() Here, automs_hpic_pos is obtained and saved followed the feature_extraction steps.","title":"Statistical Analysis"},{"location":"statistics/#data-combination","text":"Data combination in metabolomics refers to the integration of metabolomics datasets obtained from different ionization modes, such as positive and negative modes. Combining data from multiple ionization modes can provide a more comprehensive view of the metabolome and improve the coverage and reliability of metabolite identification. AutoMS achieves this by append_feature_table function, Here's an example code snippet: # Load and export features for positive ion mode automs_hpic_pos = automs.AutoMSData(ion_mode='positive') automs_hpic_pos.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_positive.project\") automs_hpic_pos = automs_hpic_pos.export_features() # Load and export features for negative ion mode automs_hpic_neg = automs.AutoMSData(ion_mode='negative') automs_hpic_neg.load_project(\"E:/Data/Guanghuoxiang/AutoMS_processing/guanghuoxiang_hpic_negative.project\") automs_hpic_neg = automs_hpic_neg.export_features() # Merge positive and negative features automs_hpic_feat = automs.AutoMSFeature() automs_hpic_feat.append_feature_table(automs_hpic_pos) automs_hpic_feat.append_feature_table(automs_hpic_neg)","title":"Data Combination"},{"location":"statistics/#preprocessing","text":"Preprocessing involves various steps to transform raw metabolomics data into a suitable format for analysis. It aims to reduce noise, correct systematic biases, and normalize the data. The preprocessing steps include: Data cleaning: Removing missing values and outliers. Imputation: Estimating missing values based on statistical methods. Data normalization: Scaling the data to account for differences in sample concentration or instrument response. Correlation Evaluation: Calculate correlations between QC samples, evaluating the experimental consistency. Here's an example code snippet: # Information of samples qc_samples = ['QC-{}'.format(i) for i in range(1,6)] group_info = { 'QC': ['QC-{}'.format(i) for i in range(1,6)], # QC group 'PX_L': ['PX-L-{}'.format(i) for i in range(1,7)], # Leaf of PX 'PX_S': ['PX-S-{}'.format(i) for i in range(1,7)], # Stem of PX 'ZX_L': ['ZX-L-{}'.format(i) for i in range(1,7)], # Leaf of ZX 'ZX_S': ['ZX-S-{}'.format(i) for i in range(1,7)], # Stem of ZX 'NX_L': ['NX-L-{}'.format(i) for i in range(1,7)], # Leaf of NX 'NX_S': ['NX-S-{}'.format(i) for i in range(1,7)] # Stem of NX } # Preprocessing automs_hpic_feat.preprocessing( impute_method='KNN', outlier_threshold=3, rsd_threshold=0.3, min_frac=0.5, qc_samples=qc_samples, group_info=group_info ) # Refine annotated table and remove repetitive annotations automs_hpic_feat.refine_annotated_table() Parameters : preprocessing impute_method (str): The imputation method to use. outlier_threshold (float): The threshold for outlier removal. rsd_threshold (float): The threshold for relative standard deviation (RSD) filtering. min_frac (float): The minimum fraction of non-missing values required for a feature to be retained. qc_samples (list): The list of QC sample names. group_info (dict): The dictionary containing group information for sample grouping. args: Additional keyword arguments for the preprocessing method. Supported similarity method : 'Low value': The missing values are imputed with a low value. 'Mean': The mean imputation method replaces missing values with the mean value of the corresponding feature. 'Median': Similar to mean imputation, the median imputation method replaces missing values with the median value of the corresponding feature. 'KNN': K-nearest neighbors (KNN) imputation imputes missing values by considering the values of the k-nearest neighbors in the feature space. 'Iterative RF': Iterative Random Forest (RF) imputation is an iterative imputation method. It builds a random forest model to predict the missing values based on other features. 'Iterative BR': Iterative Bayesian Ridge (BR) imputation is another iterative imputation method. It uses a Bayesian Ridge regression model to estimate the missing values based on other features. 'Iterative SVR': Iterative Support Vector Regression (SVR) imputation is an iterative method that uses support vector regression to predict missing values. It builds a regression model using non-missing values as the training data and predicts the missing values.","title":"Preprocessing"},{"location":"statistics/#dimensional-reduction-analysis","text":"Dimensionality reduction analysis is a technique used in machine learning and data analysis to reduce the dimensionality of a dataset while preserving its important structures and patterns. It aims to overcome the curse of dimensionality by transforming high-dimensional data into a lower-dimensional space. Principal Component Analysis (PCA) : PCA is a widely used linear dimensionality reduction technique. It identifies the directions in the data that capture the maximum variance, known as principal components. These components form a new orthogonal coordinate system, where the data can be represented with fewer dimensions while retaining most of the original information. t-Distributed Stochastic Neighbor Embedding (t-SNE) : t-SNE is a nonlinear dimensionality reduction method that emphasizes the preservation of local structure and relationships between data points. It maps high-dimensional data to a lower-dimensional space by modeling the similarity between data points in the original space and the lower-dimensional space. t-SNE is particularly useful for visualizing clusters and identifying patterns in complex datasets. Uniform Manifold Approximation and Projection (UMAP) : UMAP is a nonlinear dimensionality reduction algorithm that preserves both local and global structure. It constructs a high-dimensional graph representation of the data and optimizes a low-dimensional graph representation that captures the same topological structure. UMAP is known for its scalability and ability to preserve complex data relationships. Here's an example code snippet: automs_hpic_feat.perform_dimensional_reduction(group_info = group_info, method = 'PCA', annotated_only = True) automs_hpic_feat.perform_dimensional_reduction(group_info = group_info, method = 'tSNE', annotated_only = True) automs_hpic_feat.perform_dimensional_reduction(group_info = group_info, method = 'uMAP', annotated_only = True) Parameters : perform_dimensional_reduction group_info (dict): The dictionary containing group information for sample grouping. method (str): The dimensional reduction method to use (e.g., 'PCA', 'tSNE', 'uMAP'). annotated_only (bool): Whether to use only the annotated feature table for dimensional reduction. args: Additional keyword arguments for the dimensional reduction method.","title":"Dimensional Reduction Analysis"},{"location":"statistics/#t-test-analysis","text":"T-test analysis is a statistical method used to compare the means of two groups and determine if there is a significant difference between them. It is commonly used in hypothesis testing to assess whether the difference observed between two sample means is likely to occur due to random chance or if it represents a true difference in the population means. AutoMS conduct T-Test by perform_T_Test function. Multi test correlation is integrated, and volcano plot is carry out automatically. Here's an example code snippet: group_info = {'PX_L': ['PX-L-{}'.format(i) for i in range(1,7)], 'ZX_L': ['ZX-L-{}'.format(i) for i in range(1,7)]} automs_hpic_feat.perform_T_Test(group_info = group_info, , annotated_only = True, alpha=0.05, method='fdr_bh') Parameters : perform_T_Test group_info (dict): The dictionary specifying group information for sample grouping. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. alpha (float): significance level to apply. method (str): multiple testing correction method to apply.","title":"T-Test Analysis"},{"location":"statistics/#multivariate-statistical-analysis","text":"The multivariate statistical analysis methods, including PLS-DA, RF, and Gradient Boosting, provide valuable tools for feature selection, classification, and predictive modeling in metabolomics research. They aid in understanding the underlying patterns and discriminating features in large and complex metabolomics datasets, facilitating biomarker discovery, sample classification, and interpretation of metabolite associations with different conditions or phenotypes. Partial Least Squares Discriminant Analysis (PLS-DA) : PLS-DA is a supervised multivariate technique commonly used in metabolomics to classify samples into predefined groups based on their metabolite profiles. It identifies the metabolites that contribute the most to the separation between groups and creates a predictive model. PLS-DA combines features of both principal component analysis (PCA) and linear regression to maximize the separation between groups while considering the relationship between metabolites and sample classes. Random Forest (RF) : RF is a machine learning algorithm widely applied in metabolomics for classification and feature selection. It constructs an ensemble of decision trees and combines their predictions to make accurate classifications. RF can handle high-dimensional data and identify the most important metabolites for classification, allowing for the interpretation of discriminatory features. Gradient Boosting : Gradient boosting is another machine learning technique commonly used in metabolomics, particularly with algorithms like XGBoost or LightGBM. Gradient boosting sequentially trains a series of weak models (usually decision trees) by focusing on the samples that were not well predicted by previous models. The weak models are then combined to create a strong predictive model that can accurately classify samples or predict their properties. Gradient boosting can handle complex relationships and capture non-linear patterns in metabolomics data. Here's an example code snippet: automs_hpic_feat.perform_PLSDA(group_info = group_info, n_components = 3, n_permutations = 1000, annotated_only = True, loo_test = True, permutation_test = True) automs_hpic_feat.perform_GradientBoost(group_info = group_info, annotated_only = True, loo_test = True, model = 'XGBoost', n_estimators = 500) automs_hpic_feat.perform_RandomForest(group_info = group_info, annotated_only = True, loo_test = True, n_estimators = 500, max_depth = 10) Parameters : perform_PLSDA group_info (dict): The dictionary specifying group information for sample grouping. n_components (int): The number of components to use. Default is 2. n_permutations (int): The number of permutations to perform for permutation test. Default is 1000. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. loo_test (bool): Flag indicating whether to perform leave-one-out test. Default is True. permutation_test (bool): Flag indicating whether to perform permutation test. Default is True. perform_GradientBoost model (str): The gradient boosting model to use ('XGBoost' or 'LightGBM'). Default is 'XGBoost'. group_info (dict): The dictionary specifying group information for sample grouping. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. loo_test (bool): Flag indicating whether to perform leave-one-out test. Default is True. args: Additional arguments to be passed to the Gradient Boosting analysis. perform_RandomForest group_info (dict): The dictionary specifying group information for sample grouping. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. loo_test (bool): Flag indicating whether to perform leave-one-out test. Default is True. args: Additional arguments to be passed to the Random Forest analysis.","title":"Multivariate Statistical Analysis"},{"location":"statistics/#heatmap-of-biomarkers","text":"A heatmap of metabolite biomarkers is a graphical representation that visualizes the relative abundance or expression levels of metabolites across different samples or conditions. It provides a comprehensive overview of the patterns and trends in metabolite profiles, highlighting the metabolites that show significant differences or associations with specific groups or conditions. In a heatmap, each row represents a metabolite, and each column represents a sample or condition. The intensity of color or shading in each cell of the heatmap reflects the abundance or expression level of the corresponding metabolite in the respective sample or condition. Typically, a color scale is used, where higher values are represented by darker or brighter colors, and lower values are represented by lighter or muted colors. Here's an example code snippet: # This step should after perform T-Test analysis or/and multivariate statistical analysis automs_hpic_feat.select_biomarker(criterion = {'PLS_VIP': ['>', 1.5], 'RF_VIP': ['>', 0.2]}, combination = 'union') automs_hpic_feat.perform_heatmap(group_info = group_info, hide_xticks = False, hide_ytick = False) Parameters : select_biomarker criterion (dict): The dictionary specifying the criteria for biomarker selection. combination (str): The combination method for multiple criteria ('union' or 'intersection'). Default is 'union'. annotated_only (bool): Flag indicating whether to use only the annotated feature table. Default is True. perform_heatmap biomarker_only (bool): Flag indicating whether to use only the biomarker table. Default is True. group_info (dict): The dictionary specifying group information for sample grouping. hide_xticks (bool): Flag indicating whether to hide the x-axis tick labels. Default is False. hide_ytick (bool): Flag indicating whether to hide the y-axis tick labels. Default is False.","title":"HeatMap of Biomarkers"}]}